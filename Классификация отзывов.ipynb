{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4906bcb-8aa1-4467-a8f6-f992b0645990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb43016a-0ede-49ed-98dc-8213767064b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d970154-840c-4c97-a952-4637b10ea762",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_xml = open(\"news_eval_train.xml\", \"r\", encoding = \"WINDOWS-1251\")\n",
    "train_text_xml = xmltodict.parse(train_text_xml.read())\n",
    "train_json = json.loads(json.dumps(train_text_xml))\n",
    "\n",
    "test_text_xml = open(\"news_eval_test.xml\", \"r\", encoding = \"WINDOWS-1251\")\n",
    "test_text_xml = xmltodict.parse(test_text_xml.read())\n",
    "test_json = json.loads(json.dumps(test_text_xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2c728a-c454-42f9-9c34-651574753567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Меня отпустили. У Коли @nlyaskin забирают вещи и сажают. Хренникова забирает скорая, ему стало плохо в камере. Суд завтра в 15 Новая Площадь 8,стр. 3\", - написала Чирикова в своем блоге в Twitter.\"В отношении Е.Чириковой составлен административный протокол по статье 19.3 КоАП города Москвы (\"неповиновение законным требованиям сотрудникам полиции\").'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw text\n",
    "train_json[\"document\"][\"sentence\"][1][\"speech\"][\"#text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e8f6d4-a275-48a8-bce6-9cab5cc8b810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rating\n",
    "train_json[\"document\"][\"sentence\"][1][\"evaluation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f0789e-9df4-4a77-88d8-68e3203d08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for elem in enumerate(train_json[\"document\"][\"sentence\"]):\n",
    "    # print(elem[1])\n",
    "    raw_text = elem[1][\"speech\"][\"#text\"]\n",
    "    rating = elem[1][\"evaluation\"]\n",
    "    if rating in [\"-\", \"0\", \"+\"]:\n",
    "        if rating == \"-\":\n",
    "            rating = -1\n",
    "        elif rating == \"0\":\n",
    "            rating = 0\n",
    "        elif rating == \"+\":\n",
    "            rating = 1\n",
    "    else:\n",
    "        rating = None\n",
    "    train_data.append([raw_text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7709572e-a540-48f9-a1b8-270842beb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for elem in enumerate(test_json[\"document\"][\"sentence\"]):\n",
    "    # print(elem[1])\n",
    "    raw_text = elem[1][\"speech\"][\"#text\"]\n",
    "    rating = elem[1][\"evaluation\"]\n",
    "    if rating in [\"-\", \"0\", \"+\"]:\n",
    "        if rating == \"-\":\n",
    "            rating = -1\n",
    "        elif rating == \"0\":\n",
    "            rating = 0\n",
    "        elif rating == \"+\":\n",
    "            rating = 1\n",
    "    else:\n",
    "        rating = None\n",
    "    test_data.append([raw_text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb2f4d06-bf9f-487a-b2d5-8d7d1dd67f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ab2ea0-e73a-42b4-9b69-ece974f85ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4260"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33935b9e-315e-45cd-83ab-0bedab8df96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#убираем предложения без рейтинга\n",
    "clear_test = []\n",
    "clear_train = []\n",
    "\n",
    "for elem in test_data:\n",
    "    if elem[1] != None:\n",
    "        clear_test.append(elem)\n",
    "        \n",
    "for elem in train_data:\n",
    "    if elem[1] != None:\n",
    "        clear_train.append(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e9f6d9-0ad0-4080-b5a9-89410b617316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Посредством этих структур\\nдесяткам тысяч избирателей предлагают деньги в обмен на паспортные\\nданные и подписи за какого-либо кандидата\", - сказал\\nЧерненко.',\n",
       " -1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea6c792-f5a7-4c62-af4c-278c2d185f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Меня отпустили. У Коли @nlyaskin забирают вещи и сажают. Хренникова забирает скорая, ему стало плохо в камере. Суд завтра в 15 Новая Площадь 8,стр. 3\", - написала Чирикова в своем блоге в Twitter.\"В отношении Е.Чириковой составлен административный протокол по статье 19.3 КоАП города Москвы (\"неповиновение законным требованиям сотрудникам полиции\").'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_train[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5621209-d6b9-42f7-bacc-b0b0fede3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_words(tokens, stop_words):\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15bf063-eaf0-45af-a0a3-a3579e6c8ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#токенизация\n",
    "import re\n",
    "import pymorphy2, nltk\n",
    "morph = pymorphy2.MorphAnalyzer(lang = 'ru')\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "all_words = []\n",
    "stop_words = stopwords.words(\"russian\")\n",
    "marks = '''!()-[]{};?@#$%:'\"\\,./^&amp;*_—»«+=><°'''\n",
    "\n",
    "for elem in clear_test:\n",
    "    norm_sent = []\n",
    "    text = elem[0].strip().lower()\n",
    "    \n",
    "    # удаление знаков препинания\n",
    "    for x in text:  \n",
    "        if x in marks:  \n",
    "            text = text.replace(x, \"\")\n",
    "            \n",
    "    #удаление английских символов и цифр\n",
    "    text = re.sub(r'[a-zA-Z0-9]', \"\", text)\n",
    "    \n",
    "    text = word_tokenize(text, language = \"russian\")\n",
    "    \n",
    "    #удаление стоп-слов\n",
    "    text = filtered_words(text, stop_words)\n",
    "    \n",
    "    # нормализация\n",
    "    for word in text:\n",
    "        norm_sent.append(morph.parse(word)[0].normal_form)\n",
    "    text = norm_sent\n",
    "    \n",
    "    elem[0] = text\n",
    "    \n",
    "    all_words.extend(text)\n",
    "\n",
    "# print(all_words)\n",
    "for elem in clear_train:\n",
    "    norm_sent = []\n",
    "    text = elem[0].strip().lower()\n",
    "    \n",
    "    # удаление знаков препинания\n",
    "    for x in text:  \n",
    "        if x in marks:  \n",
    "            text = text.replace(x, \"\")\n",
    "            \n",
    "    #удаление английских символов и цифр\n",
    "    text = re.sub(r'[a-zA-Z0-9]', \"\", text)\n",
    "    \n",
    "    text = word_tokenize(text, language = \"russian\")\n",
    "    \n",
    "    #удаление стоп-слов\n",
    "    text = filtered_words(text, stop_words)\n",
    "    \n",
    "    # нормализация\n",
    "    for word in text:\n",
    "        norm_sent.append(morph.parse(word)[0].normal_form)\n",
    "    text = norm_sent\n",
    "    \n",
    "    elem[0] = text\n",
    "    \n",
    "    all_words.extend(text)\n",
    "    \n",
    "    \n",
    "all_words = sorted(list(set(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd51c1e2-49b2-4490-9bf1-c05ef1be87f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['мужество',\n",
       " 'мужик',\n",
       " 'мужской',\n",
       " 'мужчие',\n",
       " 'мужчина',\n",
       " 'мужчинаодный',\n",
       " 'музей',\n",
       " 'музейзаповедник',\n",
       " 'музейный',\n",
       " 'музенидис']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c94cfcf0-7977-42f9-be89-1374d3f5f782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22379"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words) #без нормализации было 44к"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862d5a69-733e-40dc-b3b9-2cb47bc760bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['посредством',\n",
       "  'этот',\n",
       "  'структура',\n",
       "  'десятка',\n",
       "  'тысяча',\n",
       "  'избиратель',\n",
       "  'предлагать',\n",
       "  'деньга',\n",
       "  'обмен',\n",
       "  'паспортный',\n",
       "  'дать',\n",
       "  'подпись',\n",
       "  'какоголибо',\n",
       "  'кандидат',\n",
       "  'сказать',\n",
       "  'черненко'],\n",
       " -1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26748257-dfd2-4b40-bbea-b5db4ccdfa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11788/861610473.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  clear_test = np.array(clear_test)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_11788/861610473.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  clear_train = np.array(clear_train)\n"
     ]
    }
   ],
   "source": [
    "clear_test = np.array(clear_test)\n",
    "clear_train = np.array(clear_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9346597c-d222-4ae8-aceb-e8fdcba5b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_clear_test = clear_test.copy()\n",
    "main_clear_train = clear_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86c8bb93-7aa2-45a6-b08e-996f41ab5b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['отпустить', 'коли', 'забирать', 'вещь', 'сажать', 'хренников', 'забирать', 'скорый', 'стать', 'плохо', 'камера', 'суд', 'завтра', 'новый', 'площадь', 'стр', 'написать', 'чириков', 'свой', 'блог', 'отношение', 'ечириков', 'составить', 'административный', 'протокол', 'статья', 'коап', 'город', 'москва', 'неповиновение', 'законный', 'требование', 'сотрудник', 'полиция']),\n",
       "       -1], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_clear_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e36594-147e-4f2a-9ce6-846167a4815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_clear_train is clear_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850f9a6-0ba4-4269-ae21-49c351806f9e",
   "metadata": {},
   "source": [
    "***Булевы вектора***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc809349-c6a6-4317-b64b-837e34bfdf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создание булевых векторов\n",
    "\n",
    "for elem in clear_train:\n",
    "    bool_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        bool_vec[all_words.index(word)] = 1\n",
    "        \n",
    "    elem[0] = bool_vec\n",
    "\n",
    "for elem in clear_test:\n",
    "    bool_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        bool_vec[all_words.index(word)] = 1\n",
    "        \n",
    "    elem[0] = bool_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "698e2c48-1179-4f14-bccb-830f209e1385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['отпустить', 'коли', 'забирать', 'вещь', 'сажать', 'хренников', 'забирать', 'скорый', 'стать', 'плохо', 'камера', 'суд', 'завтра', 'новый', 'площадь', 'стр', 'написать', 'чириков', 'свой', 'блог', 'отношение', 'ечириков', 'составить', 'административный', 'протокол', 'статья', 'коап', 'город', 'москва', 'неповиновение', 'законный', 'требование', 'сотрудник', 'полиция']),\n",
       "       -1], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_clear_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "367d0013-284c-4431-b892-4c95e689e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clear_train[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02a3a0b6-d2f9-42d4-8d44-6d2e009eada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model = GridSearchCV(model, {\"max_iter\" : [100, 200, 300, 400]})\n",
    "\n",
    "X = [bool_vec for bool_vec, rating in clear_train]\n",
    "y = [rating for bool_vec, rating in clear_train]\n",
    "\n",
    "\n",
    "X_test = [bool_vec for bool_vec, rating in clear_test]\n",
    "y_test = [rating for bool_vec, rating in clear_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8434b5e4-afa7-4a5d-a924-d3dbcc72d34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': [100, 200, 300, 400]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1086e2bf-47b3-45ad-a166-3ba28f54e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_['max_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6c945c9-fb92-4e5f-accf-42f15736b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77a08766-2b4c-479d-8a66-ddb04ac469ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5683661045014432 0.5937021648808222 0.586470716322116 0.5937021648808222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "f1_macro = f1_score(y_test, pred, average='macro')\n",
    "f1_micro = f1_score(y_test, pred, average='micro')\n",
    "f1_w = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "print(f1_macro, f1_micro, f1_w, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c8de8-219b-4771-a9f3-9818f0b0882d",
   "metadata": {},
   "source": [
    "***TF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ef4a1f-084a-4930-aa56-a32d621cb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test = main_clear_test.copy()\n",
    "tf_train = main_clear_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c819449a-95e7-4569-acc5-d91614cdf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рассчет TF\n",
    "\n",
    "for elem in tf_train:\n",
    "    tf_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        tf_vec[all_words.index(word)] += 1\n",
    "        \n",
    "    elem[0] = tf_vec\n",
    "\n",
    "for elem in tf_test:\n",
    "    tf_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        tf_vec[all_words.index(word)] += 1\n",
    "        \n",
    "    elem[0] = tf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8132a0f-1872-4967-b76b-24c3ab609670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(max_iter = 350)\n",
    "\n",
    "X = [tf_vec for tf_vec, rating in tf_train]\n",
    "y = [rating for tf_vec, rating in tf_train]\n",
    "\n",
    "\n",
    "X_test = [tf_vec for tf_vec, rating in tf_test]\n",
    "y_test = [rating for tf_vec, rating in tf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c70eeea3-c688-4079-8ba7-541f7fbe79d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=350)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc52c0af-c6b2-4b76-a78b-ee5adb14ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4aa7f9-e34c-4e8a-970b-98e8f1659046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5675216357691751 0.5934834900502952 0.5859657167459726 0.5934834900502952\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, pred, average='macro')\n",
    "f1_micro = f1_score(y_test, pred, average='micro')\n",
    "f1_w = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "print(f1_macro, f1_micro, f1_w, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd0ad9-6105-4599-bb3a-8872ba7271e5",
   "metadata": {},
   "source": [
    "***TF-IDF***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2536da87-aa11-4c09-9b98-dd11821e6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_test = main_clear_test.copy()\n",
    "idf_train = main_clear_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef87a4b3-1d7b-4b9b-b3b3-32de3fee34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рассчет TF-IDF\n",
    "\n",
    "#df - кол-во документов, содержащих терм\n",
    "\n",
    "df = [0] * len(all_words)\n",
    "\n",
    "for elem in idf_train:\n",
    "    for i in range(len(all_words)):\n",
    "        if all_words[i] in elem[0]:\n",
    "            df[i] += 1\n",
    "            \n",
    "for elem in idf_test:\n",
    "    for i in range(len(all_words)):\n",
    "        if all_words[i] in elem[0]:\n",
    "            df[i] += 1\n",
    "            \n",
    "df = np.array(df)\n",
    "            \n",
    "idf = np.log10(len(idf_train) / df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e5fdec0-21b4-436b-9bd5-29d330ead45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рассчет TF\n",
    "\n",
    "for elem in idf_train:\n",
    "    idf_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        idf_vec[all_words.index(word)] += 1\n",
    "    idf_vec = np.multiply(idf_vec, idf)\n",
    "        \n",
    "    elem[0] = idf_vec\n",
    "\n",
    "for elem in idf_test:\n",
    "    idf_vec = [0] * len(all_words)\n",
    "    \n",
    "    for word in elem[0]:\n",
    "        idf_vec[all_words.index(word)] += 1\n",
    "    idf_vec = np.multiply(idf_vec, idf)\n",
    "        \n",
    "    elem[0] = idf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c39a2bc-8dd1-4867-afb1-004484602ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(max_iter = 350)\n",
    "\n",
    "X = [idf_vec for idf_vec, rating in idf_train]\n",
    "y = [rating for idf_vec, rating in idf_train]\n",
    "\n",
    "\n",
    "X_test = [idf_vec for idf_vec, rating in idf_test]\n",
    "y_test = [rating for idf_vec, rating in idf_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "021a388f-7339-49ed-8658-3580ecd6b1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=350)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b9dded1-3234-4c44-b89e-e870d946782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c5ecef3-7d63-4d68-bd6f-d9c7cf5b1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566732683814627 0.5930461403892412 0.5848899693832185 0.5930461403892412\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, pred, average='macro')\n",
    "f1_micro = f1_score(y_test, pred, average='micro')\n",
    "f1_w = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "print(f1_macro, f1_micro, f1_w, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2778da5-57e8-481e-a2ac-769f37bfb24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56721ecc-359c-4bdd-b97f-c7e92c909840",
   "metadata": {},
   "source": [
    "***Отчет***\n",
    "\n",
    "\n",
    "В данном задании было реализовано обучение модели с использованием булевых векторов, TF и TF-IDF. Во всех трех случаях моделью выбрана LogisticRegression. Дополнительно тестировался SGDClassifier, но он показал результат заметно хуже, в связи с чем был удален из кода.\n",
    "\n",
    "\n",
    "Accuracy на всех трех вариантах представления данных держится около 0.59, меры F1_macro, F1_micro и F1_weighted соответственно на уровне 0.56, 0.59 и 0.58.\n",
    "\n",
    "\n",
    "Из предостваленного XML файла в данные для обучения был выделен только текст и его рейтинг (\"-\", \"0\", \"+\", остальные игнорировались вместе с текстом). Из полученных данных были удалены латинские символы, цифры, знаки препинания и другие знаки (marks). После разбиения на слова была проведена нормализация, что существенно уменьшило размер вектора уникальных слов: с 44 тысяч до 22 тысяч слов. Текст рассматривался как мешок слов (bag-of-words), без учета контекста.\n",
    "\n",
    "\n",
    "Был протестирован метод Grid Search на булевых векторах, который почему-то выполняется крайне долго. При ручном запуске сети с параметром max_iter = 350 сеть обучалась около минуты, обучение с Grid Search на 100, 200, 300 и 400 время обучения достигало 15 минут, причем оптимальным параметром оказывался max_iter = 100, в связи с чем в других представлениях данных Grid Search не применялся. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce92fb0-06cd-4137-8caa-78c9c244be5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
